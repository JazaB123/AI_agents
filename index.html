<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>AI Agents</title>
    <link rel="stylesheet" href="style.css">
    <link href='https://unpkg.com/boxicons@2.1.4/css/boxicons.min.css' rel='stylesheet'>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300..700&display=swap" rel="stylesheet">
</head>

<body>
    <aside class="sidebar">
        <nav>
            <ul class="links">
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#react-loop">LLMs for Acting</a></li>
                <li><a href="#tool-usage">Tool Usage</a></li>
                <li><a href="#software_engineering">Software Engineering</a></li>
                <li><a href="#risks">Risks</a></li>
                <li><a href="#about">About Us</a></li>
            </ul>
        </nav>
    </aside>

    <div class="page-title">AI Agents</div>

    <section id="introduction">
        <div class="project-box introduction">
            <p class="intro-lede">Recent public, academic, and industry interest in AI agents reflects a broader shift
                in system capabilities—from rational agents operating over explicit models to general-purpose
                <em>language agents</em> that coordinate tools and learn from data. Following the launch of large-scale
                generative models, agent design moved beyond rule-bound settings toward more flexible, learning-driven
                architectures that adapt to context.
            </p>

            <!-- Now & Then: Compact Left→Right Timeline -->
            <div class="now-then">
                <h3>Now & Then</h3>
                <div class="nt-timeline">
                    <div class="nt-line" aria-hidden="true"></div>

                    <div class="nt-item left">
                        <div class="nt-year">1992</div>
                        <div class="quote-bubble">
                            <p>“Agent-based computing (ABC) is likely to be the <strong>next significant
                                    breakthrough</strong> in software development.”</p>
                            <small>
                                — Sargent (1992) · via
                                <a class="source-link" href="https://doi.org/10.1017/S0269888900008122" target="_blank"
                                    rel="noopener">Wooldridge &amp; Jennings (1995)</a>
                            </small>
                        </div>
                    </div>

                    <div class="nt-item right">
                        <div class="nt-year">1995</div>
                        <div class="quote-bubble">
                            <p>“[…] agent technology is, at the time of writing, one of the <strong>most active areas of
                                    research</strong> in AI and computer science generally.”</p>
                            <small>
                                — <a class="source-link" href="https://doi.org/10.1017/S0269888900008122"
                                    target="_blank" rel="noopener">Wooldridge &amp; Jennings (1995)</a>
                            </small>
                        </div>
                    </div>

                    <div class="nt-item left">
                        <div class="nt-year">2025</div>
                        <div class="quote-bubble">
                            <p>“AI Agents are <strong>revolutionizing</strong> the software development life cycle.”</p>
                            <small>
                                — <a class="source-link"
                                    href="https://thenewstack.io/ai-agents-are-finally-starting-to-revolutionize-the-software-development-lifecycle/"
                                    target="_blank" rel="noopener">The New Stack (Sayers, 2025)</a>
                            </small>
                        </div>
                    </div>
                </div>
            </div>
            <hr class="intro-sep" aria-hidden="true" />
            <p class="section-lede transition-note">Agents are not a new idea; their prominence today reflects renewed
                feasibility rather than novelty. What has changed is the substrate: large language models,
                tool‑augmented execution, and scalable memory make long‑standing agent designs practical at last. This
                invites a natural question—why so much renewed interest, and what, if anything, is fundamentally
                different in the underlying technology?</p>

            <!-- Vision of “Information Agents” (1995) -->
            <div class="info-vision">
                <h3>Vision of “Information Agents” (1995)</h3>
                <div class="section-split iv-grid">
                    <figure class="iv-figure reveal">
                        <div class="quote-bubble">
                            <p class="dimmed">“[…] access to at least one, and potentially <strong>many information
                                    sources</strong>, and [be] able to <strong>collate and manipulate
                                    information</strong> obtained from these sources to <strong>answer queries</strong>
                                posed by users and other information agents […].<br><br> A typical scenario is that of a
                                user who has heard about somebody at Stanford […] The agent is asked to investigate,
                                and, after a careful search of various FTP sites, <strong>return with an appropriate
                                    technical report</strong> […]”</p>
                            <small>— <a class="source-link" href="https://doi.org/10.1017/S0269888900008122"
                                    target="_blank" rel="noopener">Wooldridge &amp; Jennings (1995)</a></small>
                        </div>
                    </figure>
                    <div class="iv-text">
                        <p class="section-lede">In the mid‑1990s, researchers outlined “information agents” that could
                            search across multiple sources, integrate results, and return useful answers. Tooling
                            constraints meant this remained largely aspirational then, but the design
                            intuition—delegating web search, collation, and retrieval—anticipates today’s language‑agent
                            architectures.</p>
                    </div>
                </div>
            </div>

            <!-- “Deep Research” (2025) -->
            <div class="deep-research" id="deep-research">
                <h3>“Deep Research” (2025)</h3>
                <div class="section-split dr-grid">
                    <div class="dr-points reveal">
                        <p class="section-lede">Contemporary research agents operationalize the 1995 vision: an LLM
                            plans and explains steps, while an internal agentic framework coordinates tools (web search,
                            browsing, citation retrieval) and memory to produce sourced answers.</p>
                        <ul>
                            <li><strong>Exactly the workflow Wooldridge &amp; Jennings imagined</strong>—nearly three
                                decades later.</li>
                            <li><strong>LLM + agentic framework</strong> guide tool use (web search, step planner,
                                citation retriever).</li>
                            <li>Trace back to <strong>WebGPT</strong> (Nakano et al., 2021):
                                <a class="source-link" href="https://arxiv.org/abs/2112.09332" target="_blank"
                                    rel="noopener">arXiv:2112.09332</a>
                            </li>
                            <li>Actions and references are <strong>limited</strong> and <strong>constrained</strong> to
                                a specific browsing environment.</li>
                        </ul>
                        <p class="small-note">Optional reading: <a class="source-link"
                                href="https://chatgpt.com/share/6865922b-ee64-800d-8e2a-de0ecc5d73ae" target="_blank"
                                rel="noopener">the original conversation on ChatGPT</a>.</p>
                    </div>
                    <figure class="dr-figure reveal">
                        <img class="zoomable" src="images/1/deep_research_example.png"
                            alt="Deep Research example output" />
                        <figcaption>Web‑augmented research assistant producing a sourced answer.</figcaption>
                    </figure>
                </div>
            </div>

            <hr class="intro-sep" aria-hidden="true" />



            <!-- What is an Agent? Mini visual -->
            <div class="agent-mini">
                <h3>What is an Agent?</h3>
                <p class="section-lede">An agent <em>perceives</em> and <em>acts</em> in an environment—classically,
                    “anything that can be viewed as perceiving its environment through sensors and acting upon that
                    environment through actuators” (<a class="source-link"
                        href="https://elibrary.pearson.de/book/99.150005/9781292401171" target="_blank"
                        rel="noopener">Russell &amp; Norvig, 2021</a>). It is <strong>rational</strong> when it chooses
                    actions that maximize expected performance given what it knows. In practice, we implement an
                    <strong>agent program</strong> that approximates an idealized <strong>agent function</strong>,
                    operating over the <strong>history of percepts</strong> (memory), not just the latest signal.
                </p>

                <div class="agent-explain">
                    <div class="agent-left">
                        <div class="agent-diagram">
                            <div class="diagram-wrap">
                                <img class="diagram" src="images/1/russelnorvig21.png"
                                    alt="Perceive → Think → Act loop" />
                                <button class="hotspot hs-perceive" aria-expanded="false"
                                    aria-controls="hs-perceive">Perceive</button>
                                <button class="hotspot hs-think" aria-expanded="false"
                                    aria-controls="hs-think">Think</button>
                                <button class="hotspot hs-act" aria-expanded="false" aria-controls="hs-act">Act</button>

                                <div class="callout" id="hs-perceive" role="region" aria-label="Perceive details">
                                    Sensors and inputs: camera, microphone, web‑API responses, even a text prompt for an
                                    LLM agent. The agent reasons over the <strong>entire percept history</strong> →
                                    memory.
                                </div>
                                <div class="callout" id="hs-think" role="region" aria-label="Think details">
                                    The agent function π maps percept history to actions. The <strong>agent
                                        program</strong> is a concrete approximation on hardware. Rationality is defined
                                    w.r.t. a <strong>performance measure</strong>.
                                </div>
                                <div class="callout" id="hs-act" role="region" aria-label="Act details">
                                    Actuators and outputs: motors, display/screen, mouse clicks, messages, or an LLM’s
                                    generated text/function call.
                                </div>
                            </div>
                        </div>
                        <p class="diagram-hint">(Click the buttons in the diagram to reveal details for Perceive, Think,
                            and Act.)</p>
                    </div>

                    <ul class="agent-points">
                        <li><strong>Perceive → Act</strong>: anything that senses the world and can affect it.</li>
                        <li><strong>Rationality</strong>: maximize expected performance given current knowledge.</li>
                        <li><strong>Memory</strong>: decisions depend on the <em>sequence</em> of percepts (not only the
                            latest).</li>
                    </ul>
                </div>
            </div>

            <hr class="intro-sep" aria-hidden="true" />

            <!-- Inside a Language Agent: next-token LM → finetuning → framework -->
            <div class="lm-agent reveal" id="lm-agent">
                <h3>Inside a Language Agent: next‑token LM → finetuning → framework</h3>
                <p class="section-lede">Now that we now what a <em>rational</em> agent is, we turn towards
                    <em>language</em> agents. The <strong>LM acts as the agent program</strong> that maps percept
                    history to actions. Here, <em>percepts</em> and <em>actions</em> are text: tool outputs and context
                    come in as tokens; actions go out as tokens (final answers or <strong>function calls</strong>). The
                    LM is trained with the <strong>language‑modeling objective</strong> (predict the next token). With
                    <strong>finetuning</strong> (instruction tuning, RLHF) and an <strong>agentic framework</strong>
                    (prompt builder, tools, memory, response extractor), the same LM carries out goal‑directed
                    behavior—while still being just a next‑token predictor.
                </p>

                <div class="lm-grid">
                    <div class="diagram-block">
                        <svg class="lm-svg" viewBox="0 0 980 460" role="img"
                            aria-label="Diagram: outer loop runs below from y back to x; inside: x → prompt builder → seq2seq with LM core and loop → response extractor → y; task model inside agent">
                            <defs>
                                <marker id="arrow" viewBox="0 0 10 10" refX="10" refY="5" markerWidth="8"
                                    markerHeight="8" orient="auto">
                                    <path d="M 0 0 L 10 5 L 0 10 z" fill="#000" />
                                </marker>
                                <!-- Glow filter for interactive highlighting -->
                                <filter id="glow" x="-50%" y="-50%" width="200%" height="200%">
                                    <feDropShadow dx="0" dy="0" stdDeviation="2" flood-color="#048bd9"
                                        flood-opacity="0.8" />
                                </filter>
                            </defs>
                            <!-- Outermost loop: start at y (right), go below the task box, then feed back into x (left) -->
                            <path id="outerLoop" class="loop" d="M 932 245 L 932 440 L 28 440 L 28 188 L 50 188"
                                fill="none" stroke="#000" stroke-width="1" stroke-linecap="round"
                                stroke-linejoin="round" marker-end="url(#arrow)" />
                            <text x="490" y="430" class="label medium" text-anchor="middle" data-role="agent">chatbot /
                                "agent"</text>

                            <!-- Task model box -->
                            <rect id="task" x="70" y="70" rx="22" ry="22" width="850" height="320" class="box agent" />
                            <text x="760" y="380" class="label medium" data-role="agent">task model</text>

                            <!-- prompt builder -->
                            <rect id="pb" x="100" y="140" rx="14" ry="14" width="140" height="100" class="box comp" />
                            <text x="120" y="185" class="label" data-role="agent">prompt</text>
                            <text x="120" y="205" class="label" data-role="agent">builder</text>
                            <!-- input x -->
                            <text x="54" y="192" class="label italic">x</text>
                            <line x1="70" y1="188" x2="100" y2="188" class="arrow" marker-end="url(#arrow)" />

                            <!-- seq2seq container -->
                            <rect id="seq" x="280" y="120" rx="18" ry="18" width="480" height="220"
                                class="box module" />

                            <!-- <text x="520" y="358" class="label medium" text-anchor="middle">seq2seq model</text> -->
                            <text x="520" y="358" class="label medium" data-role="seq">seq2seq model</text>
                            <!-- LM core -->
                            <rect id="lmCore" x="420" y="150" rx="12" ry="12" width="210" height="140" class="box lm" />
                            <text x="525" y="230" class="label big" data-role="ntp">LM</text>

                            <!-- arrows: pb → seq, into LM, LM forward, loop back, seq → extractor -->
                            <line x1="240" y1="188" x2="280" y2="188" class="arrow" marker-end="url(#arrow)" />
                            <line x1="420" y1="188" x2="450" y2="188" class="arrow fwd" marker-end="url(#arrow)" />
                            <line x1="610" y1="230" x2="720" y2="230" class="arrow" marker-end="url(#arrow)" />
                            <circle cx="610" cy="230" r="5" class="dot" />
                            <!-- autoregressive loop inside seq2seq -->
                            <path d="M 610 230 C 660 230 660 295 500 300 C 380 305 380 220 420 188" class="loop"
                                marker-end="url(#arrow)" />
                            <text x="440" y="320" class="label medium" data-role="ntp">next‑token prediction</text>

                            <!-- response extractor and output y -->
                            <rect id="re" x="720" y="185" rx="14" ry="14" width="150" height="90" class="box comp" />
                            <text x="735" y="220" class="label" data-role="agent">response</text>
                            <text x="735" y="240" class="label" data-role="agent">extractor</text>
                            <line x1="870" y1="230" x2="920" y2="230" class="arrow" marker-end="url(#arrow)" />
                            <text x="930" y="234" class="label italic">y</text>
                        </svg>

                        <div class="legend">
                            <button class="chip sel" data-mode="pretrain" aria-pressed="true">Pretraining: next‑token
                                LM</button>
                            <button class="chip" data-mode="finetune">Finetuning: SFT / RLHF</button>
                            <button class="chip" data-mode="framework">Framework: tools · memory · planner</button>
                        </div>
                    </div>

                    <div class="explain" id="lmExplain">
                        <div class="pane show" data-for="pretrain">
                            <h4>Pretraining: next‑token LM</h4>
                            <p>Optimize log‑likelihood of text: maximize p(w<sub>t</sub> | w<sub>1..t‑1</sub>). The LM
                                learns broad world knowledge, patterns, and procedures from sequences, but it’s still
                                just predicting the next token.</p>
                        </div>
                        <div class="pane" data-for="finetune">
                            <h4>Finetuning: instruction following</h4>
                            <p>Supervised instruction tuning and RLHF align the LM to follow instructions and prefer
                                helpful/honest/harmless outputs. The objective is still token prediction—only the
                                data/feedback change.</p>
                        </div>
                        <div class="pane" data-for="framework">
                            <h4>Agentic framework around the LM</h4>
                            <ul>
                                <li><strong>Prompt builder</strong>: formats x, inserts context/tools.</li>
                                <li><strong>Tools & memory</strong>: retrieval, browsing, code, scratchpads.</li>
                                <li><strong>Response extractor</strong>: parse function calls, citations, or final y.
                                </li>
                            </ul>
                            <p>The LM remains a next‑token predictor; the framework makes it <em>agentic</em>.</p>
                            <p class="small-note">This is the scaffolding behind <a href="#deep-research">Deep
                                    Research</a>: the framework actuates tools (web search, browsing, retrieval,
                                citation extraction) to plan, verify, and produce sourced answers.</p>
                        </div>
                    </div>
                </div>
            </div>

            <hr class="intro-sep" aria-hidden="true" />
            <!-- From Rational → Language Agents (polished contrast) -->
            <section class="contrast-agents reveal" aria-labelledby="contrastTitle">
                <h3 id="contrastTitle">From Rational → Language Agents</h3>
                <div class="contrast-matrix" role="table" aria-label="Rational vs Language agents">
                    <div class="matrix-head">
                        <div class="th" role="columnheader">Rational (classic)</div>
                        <div class="th" role="columnheader">Language (LLM‑based)</div>
                    </div>
                    <div class="row" role="row">
                        <div class="cell" role="cell">
                            <div class="k">Percepts/Actions</div>
                            <div class="v">physical sensors & actuators</div>
                        </div>
                        <div class="cell" role="cell">
                            <div class="k">Percepts/Actions</div>
                            <div class="v"><strong>text tokens</strong> and <strong>JSON function calls</strong></div>
                        </div>
                    </div>
                    <div class="row" role="row">
                        <div class="cell" role="cell">
                            <div class="k">World model</div>
                            <div class="v">hand‑crafted, task‑specific</div>
                        </div>
                        <div class="cell" role="cell">
                            <div class="k">World model</div>
                            <div class="v"><strong>pretraining prior</strong> on trillion‑token corpora</div>
                        </div>
                    </div>
                    <div class="row" role="row">
                        <div class="cell" role="cell">
                            <div class="k">Policy</div>
                            <div class="v">rules/search over explicit model</div>
                        </div>
                        <div class="cell" role="cell">
                            <div class="k">Policy</div>
                            <div class="v">next‑token LM + finetuning; <strong>ICL</strong> for fast adaptation</div>
                        </div>
                    </div>
                    <div class="row" role="row">
                        <div class="cell" role="cell">
                            <div class="k">Adaptation</div>
                            <div class="v">re‑engineering for new tasks</div>
                        </div>
                        <div class="cell" role="cell">
                            <div class="k">Adaptation</div>
                            <div class="v">few‑shot examples in context; no recompilation</div>
                        </div>
                    </div>
                    <div class="row" role="row">
                        <div class="cell" role="cell">
                            <div class="k">Tools</div>
                            <div class="v">bespoke, tightly integrated per task</div>
                        </div>
                        <div class="cell" role="cell">
                            <div class="k">Tools</div>
                            <div class="v">planner orchestrates search, retrieval, code, browsing</div>
                        </div>
                    </div>
                </div>

                <p class="section-lede" style="margin-top:.9em">In short, the <em>loop</em> stays the same but the
                    <em>medium</em> flips to language. Percepts and actions are text (including structured function
                    calls), the world model is a broad <strong>pretraining prior</strong>, and <strong>in‑context
                        learning</strong> allows quick adaptation. Language becomes the uniform interface for tools and
                    components. This shift explains the renewed interest: it’s not just hype, but a <strong>different
                        substrate and architecture</strong> enabling practical language agents.
                </p>
            </section>

            <hr class="intro-sep" aria-hidden="true" />


            <style>
                /* Introduction section scoped styles */
                .introduction .muted {
                    opacity: 0.7;
                }

                /* Restore emphasis overridden by global * selector */
                .introduction strong,
                .introduction b {
                    font-weight: 700 !important;
                }

                .introduction em,
                .introduction i {
                    font-style: italic !important;
                }

                .intro-lede {
                    opacity: 0.9;
                    max-width: 900px;
                }

                .section-lede {
                    opacity: 0.9;
                    max-width: 900px;
                    margin-top: .4em;
                }

                /* Now & Then vertical timeline (compact spacing) */
                .now-then {
                    margin-top: 1.2em;
                }

                .nt-timeline {
                    position: relative;
                    padding: .25em 0 .9em;
                }

                .nt-line {
                    position: absolute;
                    left: 50%;
                    top: 0;
                    bottom: 0;
                    width: 2px;
                    background: #000;
                    transform: translateX(-50%);
                    opacity: 0.12;
                }

                .nt-item {
                    position: relative;
                    width: 100%;
                    padding: .35em 1em 1em;
                    opacity: 0;
                    transform: translateY(8px);
                    transition: opacity .4s ease, transform .4s ease;
                }

                .nt-item.show {
                    opacity: 1;
                    transform: none;
                }

                .nt-item.left {
                    text-align: left;
                }

                .nt-item.right {
                    text-align: right;
                }

                .nt-year {
                    position: absolute;
                    left: 50%;
                    transform: translateX(-50%);
                    font-weight: 700;
                    letter-spacing: 1px;
                    top: 0;
                    background: #fff;
                    padding: 0 .35em;
                }

                .quote-bubble {
                    display: inline-block;
                    max-width: 460px;
                    background: #fff;
                    border: 2px solid #000;
                    border-radius: .9em;
                    padding: .7em .9em;
                    position: relative;
                    box-shadow: 3px 3px 0 #000;
                }

                .quote-bubble p {
                    margin-bottom: .45em;
                }

                .quote-bubble small {
                    opacity: 0.75;
                }

                .source-link {
                    text-decoration: underline;
                    color: inherit;
                }

                .intro-sep {
                    border: 0;
                    height: 1px;
                    background: rgba(0, 0, 0, .12);
                    margin: 1.2em 0 0.8em;
                }

                /* Split layout used by Vision + Deep Research */
                .section-split {
                    margin-top: .6em;
                    display: grid;
                    grid-template-columns: minmax(320px, 1fr) minmax(360px, 1.1fr);
                    gap: 1.6em;
                    align-items: stretch;
                }

                /* Info Agents (1995) */
                .info-vision {
                    margin-top: 2em;
                }

                .info-vision .iv-grid {
                    align-items: start;
                }

                .dimmed {
                    opacity: 0.85;
                }

                /* No yellow highlights — bold text only */
                .hl {
                    font-weight: 700;
                    opacity: 1;
                    background: none;
                }

                .callouts {
                    margin-top: .8em;
                    display: flex;
                    flex-wrap: wrap;
                    gap: .6em;
                }

                .chip {
                    border: 1px solid #000;
                    border-radius: 999px;
                    padding: .35em .7em;
                    background: #fff;
                    box-shadow: 2px 2px 0 #000;
                    font-size: .95em;
                }

                .editor-note {
                    margin-top: .5em;
                    font-style: italic;
                    opacity: 0.85;
                }

                /* Deep Research (2025) */
                .deep-research {
                    margin-top: 2em;
                }

                .dr-grid {
                    grid-template-columns: minmax(360px, 1.1fr) minmax(320px, 1fr);
                }

                /* Ensure the bullet list stays one column and is neatly spaced */
                .introduction .dr-points ul {
                    margin: .2em 0 0;
                    padding-left: 1.2em;
                    list-style: disc outside !important;
                    display: block !important;
                    column-count: 1 !important;
                    -webkit-column-count: 1 !important;
                    column-gap: normal !important;
                    grid-template-columns: none !important;
                }

                .introduction .dr-points li {
                    margin: 0 0 .7em;
                    line-height: 1.45;
                    break-inside: avoid;
                }

                .dr-points .small-note {
                    margin-top: .8em;
                }

                .dr-figure {
                    align-self: start;
                }

                .dr-figure img {
                    width: 75%;
                    height: auto;
                    object-fit: cover;
                    border-radius: .5em;
                    cursor: zoom-in;
                    display: block;
                    margin: 0 auto;
                }

                .dr-figure figcaption {
                    text-align: center;
                    opacity: 0.75;
                    margin-top: .4em;
                    font-size: .95em;
                }

                .small-note {
                    opacity: 0.75;
                    margin-top: .6em;
                }

                /* Lightbox for zoomable images */
                .img-lightbox {
                    position: fixed;
                    inset: 0;
                    background: rgba(0, 0, 0, .75);
                    display: none;
                    place-items: center;
                    z-index: 9999;
                }

                .img-lightbox.show {
                    display: grid;
                }

                .img-lightbox img {
                    max-width: 92vw;
                    max-height: 92vh;
                    border-radius: .6em;
                    box-shadow: 0 12px 40px rgba(0, 0, 0, .45);
                }

                .img-lightbox .lb-close {
                    position: absolute;
                    top: 12px;
                    right: 16px;
                    background: #fff;
                    border: 2px solid #000;
                    border-radius: .4em;
                    padding: .15em .45em;
                    font-size: 1.1em;
                    cursor: pointer;
                }

                /* LM inner workings section */
                .lm-agent {
                    margin-top: 2em;
                }

                .lm-grid {
                    margin-top: .8em;
                    display: grid;
                    grid-template-columns: minmax(420px, 1.1fr) minmax(360px, 1fr);
                    gap: 1.6em;
                    align-items: start;
                }

                .lm-svg {
                    width: 100%;
                    height: auto;
                    background: #fff;
                    border: 1px solid #eee;
                    border-radius: .6em;
                }

                .box {
                    fill: #fff;
                    stroke: #000;
                    stroke-width: 2px;
                }

                .box.agent {
                    fill: #f7fbff;
                }

                .box.module {
                    fill: #f1f8ff;
                }

                .box.comp {
                    fill: #fff;
                }

                .box.lm {
                    fill: #fff;
                }

                .label {
                    font-size: 13px;
                    fill: #000;
                }

                .label.small {
                    font-size: 12px;
                    opacity: .8;
                }

                .label.big {
                    font-size: 22px;
                    font-weight: 700;
                    text-anchor: middle;
                }

                .label.italic {
                    font-style: italic;
                }

                .arrow {
                    stroke: #000;
                    stroke-width: 2px;
                    marker-end: url(#arrow);
                }

                .loop {
                    fill: none;
                    stroke: #000;
                    stroke-width: 2px;
                }

                .dot {
                    fill: #000;
                }

                /* Improve readability of SVG labels */
                .lm-svg .label {
                    font-size: 18px;
                    font-family: ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, Helvetica, Arial, "Noto Sans", "Liberation Sans";
                    fill: #000;
                    font-weight: 500;
                }

                .lm-svg .label.small {
                    font-size: 16px;
                    font-weight: 500;
                }

                .lm-svg .label.big {
                    font-size: 30px;
                    font-weight: 700;
                }

                .lm-svg .label.italic {
                    font-style: italic;
                }

                /* Mode highlights */
                .lm-agent[data-mode="pretrain"] .lm-svg .fwd,
                .lm-agent[data-mode="pretrain"] .lm-svg .loop:not(#outerLoop) {
                    stroke-width: 3px;
                }

                .lm-agent[data-mode="finetune"] .lm-svg #lmCore {
                    stroke-width: 3px;
                }

                .lm-agent[data-mode="framework"] .lm-svg #pb,
                .lm-agent[data-mode="framework"] .lm-svg #re {
                    stroke-width: 3px;
                }

                .legend {
                    display: flex;
                    gap: .6em;
                    flex-wrap: wrap;
                    margin-top: .6em;
                }

                .chip {
                    border: 1px solid #000;
                    border-radius: 999px;
                    padding: .35em .7em;
                    background: #fff;
                    box-shadow: 2px 2px 0 #000;
                    cursor: pointer;
                }

                .chip.sel {
                    background: #000;
                    color: #fff;
                    box-shadow: none;
                }

                .explain .pane {
                    display: none;
                }

                .explain .pane.show {
                    display: block;
                }


                /* Generic reveal */
                .reveal {
                    opacity: 0;
                    transform: translateY(8px);
                    transition: opacity .4s ease, transform .4s ease;
                }

                .reveal.show {
                    opacity: 1;
                    transform: none;
                }

                /* Tails point toward center line */
                .nt-item.left .quote-bubble {
                    margin-right: -8%;
                }

                .nt-item.right .quote-bubble {
                    margin-left: -8%;
                }

                .nt-item.left .quote-bubble::after {
                    content: "";
                    position: absolute;
                    right: -10px;
                    top: 14px;
                    border-width: 10px;
                    border-style: solid;
                    border-color: transparent transparent transparent #000;
                }

                .nt-item.left .quote-bubble::before {
                    content: "";
                    position: absolute;
                    right: -8px;
                    top: 14px;
                    border-width: 10px;
                    border-style: solid;
                    border-color: transparent transparent transparent #fff;
                    z-index: 1;
                }

                .nt-item.right .quote-bubble::after {
                    content: "";
                    position: absolute;
                    left: -10px;
                    top: 14px;
                    border-width: 10px;
                    border-style: solid;
                    border-color: transparent #000 transparent transparent;
                }

                .nt-item.right .quote-bubble::before {
                    content: "";
                    position: absolute;
                    left: -8px;
                    top: 14px;
                    border-width: 10px;
                    border-style: solid;
                    border-color: transparent #fff transparent transparent;
                    z-index: 1;
                }

                .agent-mini {
                    margin-top: 2em;
                }

                .agent-explain {
                    display: grid;
                    grid-template-columns: minmax(360px, 1.1fr) minmax(320px, 1fr);
                    gap: 1.6em;
                    align-items: start;
                }

                .agent-left {
                    display: block;
                }

                .agent-diagram {
                    max-width: 760px;
                    margin: 0 auto;
                }

                .diagram-wrap {
                    position: relative;
                    width: 75%;
                    margin: 0 auto;
                }

                .agent-diagram .diagram {
                    width: 100%;
                    border-radius: .5em;
                    display: block;
                }

                .hotspot {
                    position: absolute;
                    padding: .25em .5em;
                    font-size: .9em;
                    border: 2px solid #000;
                    border-radius: 999px;
                    background: #fff;
                    box-shadow: 2px 2px 0 #000;
                    cursor: pointer;
                }

                /* Rough positions over the diagram */
                .hs-perceive {
                    top: 6%;
                    right: 6%;
                }

                .hs-think {
                    top: 46%;
                    left: 38%;
                }

                .hs-act {
                    bottom: 12%;
                    right: 12%;
                }

                .callout {
                    position: absolute;
                    max-width: 320px;
                    background: #fff;
                    border: 1px solid #000;
                    border-radius: .5em;
                    padding: .6em .75em;
                    box-shadow: 3px 3px 0 #000;
                    opacity: 0;
                    pointer-events: none;
                    transform: translateY(6px);
                    transition: opacity .2s ease, transform .2s ease;
                    font-size: .95em;
                }

                #hs-perceive {
                    top: 14%;
                    right: 2%;
                }

                #hs-think {
                    top: 58%;
                    left: 8%;
                }

                #hs-act {
                    bottom: 22%;
                    right: 12%;
                }

                .callout.show {
                    opacity: 1;
                    transform: none;
                    pointer-events: auto;
                }

                .diagram-hint {
                    text-align: center;
                    font-size: .78em;
                    opacity: .7;
                    margin-top: .4em;
                    font-style: italic;
                }

                .agent-points {
                    margin: .4em 0 0;
                    padding-left: 1.1em;
                }

                .agent-points li {
                    margin: 0 0 .6em;
                    line-height: 1.45;
                }

                /* Contrast: From Rational → Language Agents */
                .contrast-agents {
                    margin-top: 1.4em;
                }

                .contrast-agents h3 {
                    margin-bottom: .4em;
                }

                .contrast-matrix {
                    margin-top: .6em;
                    border: 1px solid #e8e8e8;
                    border-radius: .6em;
                    overflow: hidden;
                    background: #fff;
                }

                .contrast-matrix .matrix-head {
                    display: grid;
                    grid-template-columns: 1fr 1fr;
                    background: #f7fafc;
                    border-bottom: 1px solid #e6eef7;
                }

                .contrast-matrix .th {
                    padding: .7em .9em;
                    font-weight: 700;
                }

                .contrast-matrix .row {
                    display: grid;
                    grid-template-columns: 1fr 1fr;
                }

                .contrast-matrix .cell {
                    padding: .7em .9em;
                    border-top: 1px solid #f0f3f6;
                }

                .contrast-matrix .cell .k {
                    font-weight: 600;
                    display: block;
                    margin-bottom: .15em;
                    opacity: .85;
                }

                .contrast-matrix .cell .v {
                    line-height: 1.45;
                }

                .contrast-agents code {
                    font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
                    font-size: .95em;
                }

                /* old compare styles removed in favor of contrast-agents */

                .figure-gallery {
                    margin-top: 2em;
                    display: grid;
                    grid-template-columns: repeat(3, 1fr);
                    gap: 1em;
                }

                .figure-gallery img {
                    width: 100%;
                    border-radius: 0.5em;
                }

                .figure-gallery figcaption {
                    text-align: center;
                    opacity: 0.8;
                    margin-top: 0.4em;
                    font-size: 0.95em;
                }

                .intro-summary {
                    margin-top: 2em;
                }

                .cta-row {
                    margin-top: 1em;
                    display: flex;
                    gap: 1em;
                    flex-wrap: wrap;
                }

                @media (max-width: 900px) {

                    .info-vision,
                    .deep-research {
                        margin-top: 1.5em;
                    }

                    .section-split,
                    .dr-grid {
                        grid-template-columns: 1fr;
                    }

                    .dr-figure img {
                        height: auto;
                        width: 100%;
                    }

                    .agent-explain {
                        grid-template-columns: 1fr;
                    }

                    .callout {
                        position: static;
                        transform: none;
                        opacity: 1;
                        margin-top: .5em;
                    }

                    .hotspot {
                        position: static;
                        display: inline-block;
                        margin: .25em .35em 0 0;
                    }

                    .nt-line {
                        left: 12px;
                        transform: none;
                    }

                    .nt-item {
                        width: 100%;
                        padding-left: 2.2em;
                    }

                    .nt-item .quote-bubble {
                        margin: 0;
                    }

                    .nt-item.right .quote-bubble::after {
                        left: -10px;
                        right: auto;
                        border-color: transparent #000 transparent transparent;
                    }

                    .nt-item.right .quote-bubble::before {
                        left: -8px;
                        right: auto;
                        border-color: transparent #fff transparent transparent;
                    }

                    .nt-item.right {
                        left: 0;
                        text-align: left;
                    }

                    .nt-item.right .quote-bubble::after {
                        left: -10px;
                        right: auto;
                        border-color: transparent #000 transparent transparent;
                    }

                    .nt-item.right .quote-bubble::before {
                        left: -8px;
                        right: auto;
                        border-color: transparent #fff transparent transparent;
                    }

                    .agent-grid {
                        grid-template-columns: 1fr;
                    }

                    .figure-gallery {
                        grid-template-columns: 1fr;
                    }

                    .contrast-matrix .matrix-head {
                        grid-template-columns: 1fr;
                    }

                    .contrast-matrix .row {
                        grid-template-columns: 1fr;
                    }
                }
            </style>
            <style>
                /* --- interactive highlighting (scoped to this block) --- */
                :root {
                    --accent: #048bd9;
                }

                .lm-agent .lm-svg .box,
                .lm-agent .lm-svg .arrow,
                .lm-agent .lm-svg .loop,
                .lm-agent .lm-svg .dot,
                .lm-agent .lm-svg text {
                    transition: opacity .2s ease, stroke-width .2s ease, filter .2s ease, stroke .2s ease;
                }

                /* Pretrain: dim all → highlight LM core + loop + forward arrow + label */
                .lm-agent.mode-pretrain .lm-svg .box,
                .lm-agent.mode-pretrain .lm-svg .arrow,
                .lm-agent.mode-pretrain .lm-svg .loop,
                .lm-agent.mode-pretrain .lm-svg .dot,
                .lm-agent.mode-pretrain .lm-svg text {
                    opacity: .25;
                }

                .lm-agent.mode-pretrain #lmCore,
                .lm-agent.mode-pretrain .loop:not(#outerLoop),
                .lm-agent.mode-pretrain .fwd,
                .lm-agent.mode-pretrain .dot,
                .lm-agent.mode-pretrain text[data-role="ntp"] {
                    opacity: 1;
                    stroke-width: 1;
                    stroke: var(--accent);
                    filter: url(#glow);
                }

                /* Finetune: LM + seq container edge */
                .lm-agent.mode-finetune .lm-svg .box,
                .lm-agent.mode-finetune .lm-svg .arrow,
                .lm-agent.mode-finetune .lm-svg .loop,
                .lm-agent.mode-finetune .lm-svg .dot,
                .lm-agent.mode-finetune .lm-svg text {
                    opacity: .25;
                }

                .lm-agent.mode-finetune #lmCore,
                .lm-agent.mode-finetune #seq,
                .lm-agent.mode-finetune .fwd,
                .lm-agent.mode-finetune text[data-role="seq"] {
                    opacity: 1;
                    stroke-width: 1;
                    stroke: var(--accent);
                    filter: url(#glow);
                }

                /* Framework: prompt builder + response extractor + outer loop */
                .lm-agent.mode-framework .lm-svg .box,
                .lm-agent.mode-framework .lm-svg .arrow,
                .lm-agent.mode-framework .lm-svg .loop,
                .lm-agent.mode-framework .lm-svg .dot,
                .lm-agent.mode-framework .lm-svg text {
                    opacity: .25;
                }

                .lm-agent.mode-framework #pb,
                .lm-agent.mode-framework #re,
                .lm-agent.mode-framework #task,
                .lm-agent.mode-framework #outerLoop,
                .lm-agent.mode-framework text[data-role="agent"] {
                    opacity: 1;
                    stroke-width: 1;
                    stroke: var(--accent);
                    filter: url(#glow);
                }
            </style>

            <script>
                // Now & Then (compact): Fade-in on scroll
                (function () {
                    const items = document.querySelectorAll('.now-then .nt-item');
                    const reveal = (entries, obs) => {
                        for (const entry of entries) {
                            if (entry.isIntersecting) {
                                entry.target.classList.add('show');
                                obs.unobserve(entry.target);
                            }
                        }
                    };
                    if ('IntersectionObserver' in window) {
                        const io = new IntersectionObserver(reveal, { root: null, threshold: 0.15 });
                        items.forEach(el => io.observe(el));
                    } else {
                        items.forEach(el => el.classList.add('show'));
                    }
                })();

                // LM inner workings controls
                (function () {
                    const root = document.getElementById('lm-agent');
                    if (!root) return;
                    const chips = root.querySelectorAll('.legend .chip');
                    const panes = root.querySelectorAll('.explain .pane');
                    const order = ['pretrain', 'finetune', 'framework'];
                    let userLocked = false;
                    const select = (mode) => {
                        chips.forEach(c => {
                            const sel = c.getAttribute('data-mode') === mode;
                            c.classList.toggle('sel', sel);
                            c.setAttribute('aria-pressed', sel ? 'true' : 'false');
                        });
                        panes.forEach(p => p.classList.toggle('show', p.getAttribute('data-for') === mode));
                        root.setAttribute('data-mode', mode);
                        // CSS-driven highlights via mode-*
                        root.classList.remove('mode-pretrain', 'mode-finetune', 'mode-framework');
                        root.classList.add(`mode-${mode}`);
                    };
                    // Initialize to currently selected or default to pretrain
                    const initSel = Array.from(chips).find(c => c.classList.contains('sel'))?.getAttribute('data-mode') || 'pretrain';
                    select(initSel);
                    // Autoplay: cycle every 5s unless user clicks a chip
                    let idx = order.indexOf(initSel);
                    const tick = () => {
                        if (userLocked) return;
                        idx = (idx + 1) % order.length;
                        select(order[idx]);
                    };
                    const intervalId = setInterval(tick, 12000);
                    chips.forEach(ch => ch.addEventListener('click', () => {
                        userLocked = true; // freeze on user interaction
                        const mode = ch.getAttribute('data-mode');
                        select(mode);
                    }));
                })();

                // Generic reveal for new sections
                (function () {
                    const items = document.querySelectorAll('.introduction .reveal');
                    if (!items.length) return;
                    const onReveal = (entries, obs) => {
                        for (const e of entries) {
                            if (e.isIntersecting) { e.target.classList.add('show'); obs.unobserve(e.target); }
                        }
                    };
                    if ('IntersectionObserver' in window) {
                        const io = new IntersectionObserver(onReveal, { root: null, threshold: 0.15 });
                        items.forEach(el => io.observe(el));
                    } else {
                        items.forEach(el => el.classList.add('show'));
                    }
                })();

                // Lightbox for zoomable images in this section
                (function () {
                    const imgs = document.querySelectorAll('.introduction img.zoomable');
                    if (!imgs.length) return;
                    const lb = document.createElement('div');
                    lb.className = 'img-lightbox';
                    lb.innerHTML = '<button class="lb-close" aria-label="Close">×</button><img alt="Expanded image" />';
                    document.querySelector('.project-box.introduction').appendChild(lb);
                    const lbImg = lb.querySelector('img');
                    const close = () => { lb.classList.remove('show'); lb.setAttribute('aria-hidden', 'true'); };
                    lb.addEventListener('click', (e) => { if (e.target === lb || e.target.classList.contains('lb-close')) close(); });
                    document.addEventListener('keydown', (e) => { if (e.key === 'Escape') close(); });
                    imgs.forEach(img => {
                        img.addEventListener('click', () => { lbImg.src = img.src; lb.classList.add('show'); lb.setAttribute('aria-hidden', 'false'); });
                    });
                })();

                // Agent diagram hotspots
                (function () {
                    const container = document.querySelector('.agent-diagram');
                    if (!container) return;
                    const buttons = container.querySelectorAll('.hotspot');
                    const boxes = {
                        perceive: container.querySelector('#hs-perceive'),
                        think: container.querySelector('#hs-think'),
                        act: container.querySelector('#hs-act')
                    };
                    function closeAll() {
                        Object.values(boxes).forEach(b => b.classList.remove('show'));
                        buttons.forEach(b => b.setAttribute('aria-expanded', 'false'));
                    }
                    buttons.forEach(btn => {
                        btn.addEventListener('click', () => {
                            const id = btn.classList.contains('hs-perceive') ? 'perceive' : btn.classList.contains('hs-think') ? 'think' : 'act';
                            const box = boxes[id];
                            const isOpen = box.classList.contains('show');
                            closeAll();
                            if (!isOpen) { box.classList.add('show'); btn.setAttribute('aria-expanded', 'true'); }
                        });
                    });
                    document.addEventListener('click', (e) => {
                        if (!container.contains(e.target)) closeAll();
                    });
                })();

                // Compare toggle
                (function () {
                    const btn = document.getElementById('compareToggle');
                    const panels = document.getElementById('comparePanels');
                    if (!btn || !panels) return; // section replaced by contrast view
                    btn.addEventListener('click', () => {
                        const mode = panels.dataset.mode === 'classical' ? 'language' : 'classical';
                        panels.dataset.mode = mode;
                        btn.setAttribute('aria-pressed', String(mode === 'language'));
                        // Simple visual emphasis: swap order
                        if (mode === 'language') panels.style.gridTemplateColumns = '1fr 1.2fr';
                        else panels.style.gridTemplateColumns = '1.2fr 1fr';
                    });
                })();


            </script>
        </div>

    </section>

    <section id="react-loop">

        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>AI Agents: ReAct & Reflexion</title>
            <style>
                * {
                    margin: 0;
                    padding: 0;
                    box-sizing: border-box;
                }

                body {
                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                    background: #f8f9fa;
                    color: #333;
                    line-height: 1.6;
                    padding: 20px;
                }

                .main-container {
                    max-width: 1200px;
                    margin: 0 auto;
                    display: flex;
                    flex-direction: column;
                    gap: 40px;
                }

                .container {
                    background: white;
                    border-radius: 8px;
                    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
                    overflow: hidden;
                }

                .react-header,
                .reflexion-header {
                    background: #fff;
                    color: #000;
                    padding: 1.5rem;
                    text-align: center;
                    border-bottom: 2px solid #000;
                    /* optional: adds a subtle divider */
                }

                .title {
                    font-size: 2.2em;
                    font-weight: 600;
                    margin-bottom: 10px;
                }

                .subtitle {
                    font-size: 1.1em;
                    opacity: 0.9;
                }

                .content {
                    padding: 30px;
                }

                .text-content {
                    padding: 0 30px 30px 30px;
                }

                h2,
                h3 {
                    font-weight: 600;
                    margin-top: 20px;
                    margin-bottom: 10px;
                    color: #495057;
                }

                p {
                    margin-bottom: 15px;
                }

                .iteration {
                    background: #f8f9fa;
                    border: 1px solid #dee2e6;
                    border-radius: 8px;
                    margin-bottom: 25px;
                    opacity: 0;
                    transform: translateY(20px);
                    transition: all 0.5s ease;
                }

                .iteration.show {
                    opacity: 1;
                    transform: translateY(0);
                }

                .iteration-header {
                    background: #e9ecef;
                    padding: 20px;
                    border-bottom: 1px solid #dee2e6;
                    display: flex;
                    align-items: center;
                    gap: 15px;
                }

                .iteration-number {
                    color: white;
                    border-radius: 50%;
                    width: 50px;
                    height: 50px;
                    display: flex;
                    align-items: center;
                    justify-content: center;
                    font-weight: bold;
                    font-size: 18px;
                }

                .react-section .iteration-number {
                    background: #495057;
                }

                .reflexion-section .iteration-number {
                    background: #e74c3c;
                }

                .iteration-title {
                    font-size: 1.3em;
                    font-weight: 600;
                    color: #495057;
                }

                .iteration-content {
                    padding: 25px;
                }

                .step {
                    background: white;
                    border: 1px solid #e9ecef;
                    border-radius: 6px;
                    padding: 20px;
                    margin-bottom: 15px;
                    opacity: 0;
                    transform: translateX(-20px);
                    transition: all 0.4s ease;
                    position: relative;
                }

                .reflexion-section .step {
                    padding: 15px;
                    margin-bottom: 12px;
                    transform: translateY(20px);
                }

                .step.show {
                    opacity: 1;
                    transform: translateX(0);
                }

                .reflexion-section .step.show {
                    transform: translateY(0);
                }

                .step.input-step {
                    border-left: 4px solid #007bff;
                    background: #f8f9ff;
                }

                .step.llm-step {
                    border-left: 4px solid #28a745;
                    background: #f8fff9;
                }

                .step.action-step {
                    border-left: 4px solid #ffc107;
                    background: #fffcf3;
                }

                .step.observation-step {
                    border-left: 4px solid #17a2b8;
                    background: #f3fcfd;
                }

                .step.task-step {
                    border-left: 4px solid #3498db;
                    background: #f8fbff;
                }

                .step.actor-step {
                    border-left: 4px solid #27ae60;
                    background: #f8fff9;
                }

                .step.evaluator-step {
                    border-left: 4px solid #f39c12;
                    background: #fffcf3;
                }

                .step.self-reflection-step {
                    border-left: 4px solid #9b59b6;
                    background: #fdf8ff;
                }

                .step.memory-step {
                    border-left: 4px solid #1abc9c;
                    background: #f3fdfc;
                }

                .step-label {
                    font-weight: bold;
                    font-size: 14px;
                    color: #495057;
                    margin-bottom: 10px;
                    display: flex;
                    align-items: center;
                    gap: 10px;
                }

                .reflexion-section .step-label {
                    font-size: 12px;
                    margin-bottom: 8px;
                    gap: 8px;
                }

                .step-content {
                    font-size: 15px;
                    color: #495057;
                    white-space: pre-line;
                }

                .reflexion-section .step-content {
                    font-size: 13px;
                }

                .bold-keyword {
                    font-weight: bold;
                    color: #212529;
                }

                .prompt-text {
                    font-weight: bold;
                    font-style: italic;
                    color: #0056b3;
                }

                .flow-indicator {
                    display: flex;
                    align-items: center;
                    gap: 10px;
                    margin: 20px 0;
                    opacity: 0;
                    transition: opacity 0.5s ease;
                }

                .reflexion-section .flow-indicator {
                    gap: 8px;
                    margin: 12px 0;
                }

                .flow-indicator.show {
                    opacity: 1;
                }

                .flow-box {
                    background: #e9ecef;
                    border: 2px solid #6c757d;
                    border-radius: 25px;
                    padding: 8px 16px;
                    font-weight: bold;
                    font-size: 12px;
                    color: #495057;
                }

                .reflexion-section .flow-box {
                    border-radius: 15px;
                    padding: 4px 10px;
                    font-size: 10px;
                }

                .flow-arrow {
                    font-size: 18px;
                    color: #6c757d;
                }

                .reflexion-section .flow-arrow {
                    font-size: 14px;
                }

                .decision-box {
                    background: #fff3cd;
                    border: 1px solid #ffeaa7;
                    border-radius: 6px;
                    padding: 15px;
                    margin: 15px 0;
                    text-align: center;
                    font-weight: 500;
                    color: #856404;
                    opacity: 0;
                    transform: scale(0.95);
                    transition: all 0.3s ease;
                }

                .reflexion-section .decision-box {
                    padding: 10px;
                    margin: 10px 0;
                    font-size: 12px;
                }

                .decision-box.show {
                    opacity: 1;
                    transform: scale(1);
                }

                .decision-box.success {
                    background: #d4edda;
                    border-color: #c3e6cb;
                    color: #155724;
                }

                .decision-box.failure {
                    background: #f8d7da;
                    border-color: #f5c6cb;
                    color: #721c24;
                }

                .arrow {
                    text-align: center;
                    font-size: 24px;
                    color: #6c757d;
                    margin: 15px 0;
                    opacity: 0;
                    transition: opacity 0.3s ease;
                }

                .reflexion-section .arrow {
                    font-size: 20px;
                    margin: 10px 0;
                }

                .arrow.show {
                    opacity: 1;
                }

                .final-answer {
                    background: #d4edda;
                    border: 2px solid #28a745;
                    border-radius: 8px;
                    padding: 25px;
                    text-align: center;
                    font-size: 1.4em;
                    font-weight: 600;
                    color: #155724;
                    margin-top: 30px;
                    transform: scale(0);
                    transition: transform 0.5s ease;
                }

                .reflexion-section .final-answer {
                    border-color: #27ae60;
                }

                .final-answer.show {
                    transform: scale(1);
                }

                .thinking-dots {
                    display: inline-block;
                    margin-left: 10px;
                }

                .dot {
                    display: inline-block;
                    width: 6px;
                    height: 6px;
                    border-radius: 50%;
                    margin: 0 2px;
                    animation: thinking 1.4s infinite both;
                }

                .react-section .dot {
                    background: #28a745;
                }

                .reflexion-section .dot {
                    background: #e74c3c;
                }

                .dot:nth-child(2) {
                    animation-delay: 0.2s;
                }

                .dot:nth-child(3) {
                    animation-delay: 0.4s;
                }

                @keyframes thinking {

                    0%,
                    80%,
                    100% {
                        opacity: 0.3;
                        transform: scale(0.8);
                    }

                    40% {
                        opacity: 1;
                        transform: scale(1);
                    }
                }

                .source-indicator {
                    font-size: 12px;
                    color: #6c757d;
                    font-style: italic;
                    margin-top: 8px;
                }

                .reflexion-section .source-indicator {
                    font-size: 10px;
                    margin-top: 6px;
                }

                /* Reflexion specific styles */
                .iterations-container {
                    display: flex;
                    flex-direction: column;
                    gap: 30px;
                }

                .iteration-connector {
                    position: absolute;
                    bottom: -30px;
                    left: 50%;
                    transform: translateX(-50%);
                    font-size: 24px;
                    color: #6c757d;
                    opacity: 0;
                    transition: opacity 0.5s ease;
                    z-index: 10;
                }

                .iteration-connector.show {
                    opacity: 1;
                }

                .reflexion-section .iteration {
                    position: relative;
                }

                .controls {
                    text-align: center;
                    margin-bottom: 20px;
                }

                .controls button {
                    background-color: #4CAF50;
                    /* Green */
                    border: none;
                    color: white;
                    padding: 15px 32px;
                    text-align: center;
                    text-decoration: none;
                    display: inline-block;
                    font-size: 16px;
                    margin: 4px 2px;
                    cursor: pointer;
                    border-radius: 8px;
                    transition: background-color 0.3s ease;
                }

                .react-controls button {
                    background-color: #667eea;
                }

                .reflexion-controls button {
                    background-color: #e74c3c;
                }

                .controls button:hover {
                    opacity: 0.9;
                }
            </style>
        </head>

        <body>
            <div class="main-container">
                <div class="container text-content">
                    <h1 class="title" style="text-align: center;">How AI Agents Think and Act</h1>
                    <p>
                        We're going to dive into AI agents and explore how they can reason and act within dynamic
                        environments, much like we do. Our main goal is to understand the inner workings of these
                        agents,
                        focusing on two key frameworks: ReAct and Reflexion.
                    </p>
                    <p>
                        At their core, AI agents analyze a problem, plan a course of action, and execute that plan to
                        arrive
                        at a solution. What makes this possible is their ability to use external tools, just like we use
                        Google Search or look up information in a database. But how did this "thinking and doing" become
                        a
                        reality for AI? Let's find out.
                    </p>
                </div>

                <div class="container react-section">
                    <div class="react-header">
                        <div class="title">ReAct: Reasoning + Acting</div>
                        <div class="subtitle">A framework that mimics human problem-solving.</div>
                    </div>

                    <div class="content">
                        <p>
                            ReAct is a framework that combines reasoning (using an internal monologue, or Chain of
                            Thought)
                            and acting (using external tools). Instead of simply generating a final answer, the AI
                            generates
                            a sequence of thoughts and actions.
                        </p>
                        <p>
                            Each action is a command—like a search query—that is actually executed. The result of that
                            action, an observation, is then fed back to the AI. This creates a continuous feedback loop
                            that
                            allows the agent to break down a complex problem into manageable steps, actively searching
                            for
                            information as needed.
                        </p>

                        <h3>How a ReAct Loop Works</h3>
                        <p>
                            The process follows a clear flow:
                        </p>
                        <ol>
                            <li><strong>Send Prompt to LLM:</strong> The initial query is given to the AI.</li>
                            <li><strong>LLM Replies with Text:</strong> The AI's response can include a "Thought" (its
                                internal monologue), an "Action" (a command to an external tool), or a final "Answer".
                            </li>
                            <li><strong>Execute Action:</strong> If the AI's response contains an "Action," a separate
                                component called a "Controller" executes it. This might be running a web search or
                                querying
                                a database.</li>
                            <li><strong>Get Observation:</strong> The external tool sends back an "Observation" (the
                                result
                                of the action).</li>
                            <li><strong>Append and Loop:</strong> The AI's output and the observation are appended to
                                the
                                original prompt, giving the AI new context to work with. The loop then repeats until a
                                final
                                "Answer" is generated.</li>
                        </ol>

                        <h3>ReAct Loop</h3>
                        <p>Let's see how the ReAct loop would handle the following question:</p>
                        <h3 style="text-align:center; font-style:italic;">"What is the capital of the country where the
                            Eiffel Tower is located?"</h3>

                        <div class="controls react-controls">
                            <button class="btn" onclick="startReactAnimation()">Start ReAct</button>
                        </div>

                        <div id="reactLoopContainer">
                        </div>

                        <div class="final-answer" id="reactFinalAnswer">
                            Final Output: Paris
                        </div>

                        <p style="margin-top: 30px;">
                            This process is like watching someone figure out a puzzle step by step. It's not just
                            recalling
                            facts, it's finding them. This lets the AI break down big problems, use up to the minute
                            information, and go beyond what it was initially trained on. ReAct gives the AI the ability
                            to
                            actively solve problems rather than just respond to them.
                        </p>
                    </div>
                </div>

                <div class="container reflexion-section">
                    <div class="reflexion-header">
                        <div class="title">Reflexion: Learning from Mistakes</div>
                        <div class="subtitle">A framework for self-correction and continuous improvement.</div>
                    </div>

                    <div class="content">
                        <p>
                            While ReAct is powerful, humans learn best when we make mistakes. Can an AI do the same?
                            With
                            the Reflexion framework, it absolutely can. Reflexion allows AI agents to improve over time
                            by
                            understanding why they went wrong, adding a layer of self-correction.
                        </p>

                        <h3>How a Reflexion Loop Works</h3>
                        <p>
                            The Reflexion loop starts with an Actor receiving a task and a history of its past attempts
                            (its
                            "memory"). The Actor then thinks, acts, and observes, producing a final answer.
                        </p>
                        <p>
                            Next, an Evaluator steps in. Its job is to compare the Actor's answer to the correct one. If
                            the
                            answer is incorrect, a Self-Reflection module is triggered. This module doesn't just say
                            "you're
                            wrong"; it generates specific feedback based on the entire path the AI took to get the
                            answer.
                            It tries to figure out exactly why it messed up.
                        </p>
                        <p>
                            That feedback, that reflection, is then added to the Actor's memory. The next time the Actor
                            attempts the same or a similar problem, it has this new context. This changes the way the
                            Actor
                            will think and act, allowing the loop to repeat with an an improved approach until it finds
                            the
                            right answer. This process lets the AI learn from its own specific failures.
                        </p>

                        <h3>Reflexion Loop</h3>
                        <p>Let's see how the Reflexion loop would handle the following question:</p>
                        <h3 style="text-align:center; font-style:italic;">"What is the capital of the country where the
                            Eiffel Tower is located?"</h3>

                        <div class="controls reflexion-controls">
                            <button class="btn" onclick="startReflexionAnimation()">Start Reflexion</button>
                        </div>

                        <div class="iterations-container" id="reflexionLoopContainer">
                        </div>

                        <div class="final-answer" id="reflexionFinalAnswer">
                            Final Output: "Paris" (Correct Answer)
                        </div>

                        <p style="margin-top: 30px;">
                            By adding this layer of self-reflection, we move beyond simple problem solving and into a
                            system
                            that can continuously improve its performance. The AI is not just a tool for a single task,
                            it
                            is an agent that can learn and adapt over time.
                        </p>
                    </div>
                </div>
            </div>

            <script>
                let isReactAnimating = false;
                let isReflexionAnimating = false;

                // ReAct Loop Data
                const reactIterationData = [
                    {
                        number: 1,
                        title: "First Iteration",
                        steps: [
                            {
                                type: "input",
                                icon: "📝",
                                label: "Input:",
                                content: "What is the capital of the country where the Eiffel Tower is located?"
                            },
                            {
                                type: "llm",
                                icon: "🤖",
                                label: "LLM Processing:",
                                content: "Thought: To answer this, I need to know where the Eiffel Tower is located.\nAction: Search(\"where is the Eiffel Tower?\")"
                            },
                            {
                                type: "action",
                                icon: "⚡",
                                label: "Action Execution:",
                                content: "Controller executes search action\nQuerying knowledge base/internet for Eiffel Tower location"
                            },
                            {
                                type: "observation",
                                icon: "👁️",
                                label: "Observation:",
                                content: "The Eiffel Tower is located in France.\nAppending this observation to the original prompt for next iteration."
                            }
                        ]
                    },
                    {
                        number: 2,
                        title: "Second Iteration",
                        steps: [
                            {
                                type: "input",
                                icon: "📝",
                                label: "Input (Updated with Previous Observation):",
                                content: "What is the capital of the country where the Eiffel Tower is located?\n\nKnown: The Eiffel Tower is located in France."
                            },
                            {
                                type: "llm",
                                icon: "🤖",
                                label: "LLM Processing:",
                                content: "Thought: Now I know it's in France. I need to find the capital of France.\nAction: Search(\"capital of France\")"
                            },
                            {
                                type: "action",
                                icon: "⚡",
                                label: "Action Execution:",
                                content: "Controller executes search action\nQuerying knowledge base/internet for France's capital"
                            },
                            {
                                type: "observation",
                                icon: "👁️",
                                label: "Observation:",
                                content: "The capital of France is Paris.\nAppending this observation to the prompt."
                            }
                        ]
                    },
                    {
                        number: 3,
                        title: "Third Iteration",
                        steps: [
                            {
                                type: "input",
                                icon: "📝",
                                label: "Input (Complete Context):",
                                content: "What is the capital of the country where the Eiffel Tower is located?\n\nKnown: The Eiffel Tower is located in France. The capital of France is Paris."
                            },
                            {
                                type: "llm",
                                icon: "🤖",
                                label: "LLM Processing:",
                                content: "Thought: The capital of France is Paris.\nAnswer: Paris"
                            }
                        ]
                    }
                ];

                // Reflexion Loop Data
                const reflexionIterationData = [
                    {
                        number: 1,
                        title: "First Trial",
                        steps: [
                            {
                                type: "task",
                                icon: "📋",
                                label: "Task:",
                                content: "INPUT: What country is the Eiffel Tower in and what is its capital?"
                            },
                            {
                                type: "actor",
                                icon: "🎭",
                                label: "Actor (Initial Attempt):",
                                content: "Thought: I should identify the country first, then its capital. The country is France. I believe the capital of France is Berlin.\nOutput: Berlin"
                            },
                            {
                                type: "evaluator",
                                icon: "⚖️",
                                label: "Evaluator:",
                                content: "Checking the answer 'Berlin' for the capital of France...\nThe correct capital of France is Paris, not Berlin.\nrt = 0 ❌"
                            },
                            {
                                type: "self-reflection",
                                icon: "🪞",
                                label: "Self-Reflection:",
                                content: "Reflection: \"Upon reflecting on the incorrect answer I provided, I realize that I made a factual error. While I correctly identified the Eiffel Tower's country as France, I incorrectly stated its capital as 'Berlin'. My mistake was not accurately recalling the capital of France. To better answer this question in the future, I must ensure I provide the correct capital city of France.\""
                            },
                            {
                                type: "memory",
                                icon: "🧠",
                                label: "Memory Update:",
                                content: "Memory += Reflection\nStoring: \"Upon reflecting on the incorrect answer I provided, I realize that I made a factual error. While I correctly identified the Eiffel Tower's country as France, I incorrectly stated its capital as 'Berlin'. My mistake was not accurately recalling the capital of France. To better answer this question in the future, I must ensure I provide the correct capital city of France.\""
                            }
                        ]
                    },
                    {
                        number: 2,
                        title: "Second Trial",
                        steps: [
                            {
                                type: "task",
                                icon: "📋",
                                label: "Task:",
                                content: "INPUT: What country is the Eiffel Tower in and what is its capital?"
                            },
                            {
                                type: "memory",
                                icon: "🧠",
                                label: "Memory Retrieval:",
                                content: "Task Input + Memory\nRetrieved reflection: \"Upon reflecting on the incorrect answer I provided, I realize that I made a factual error. While I correctly identified the Eiffel Tower's country as France, I incorrectly stated its capital as 'Berlin'. My mistake was not accurately recalling the capital of France. To better answer this question in the future, I must ensure I provide the correct capital city of France.\""
                            },
                            {
                                type: "actor",
                                icon: "🎭",
                                label: "Actor (Improved Attempt):",
                                content: "Thought: Based on my previous mistake, I need to correctly identify the capital of France. The Eiffel Tower is located in France. The correct capital of France is Paris.\nOutput: Paris"
                            },
                            {
                                type: "evaluator",
                                icon: "⚖️",
                                label: "Evaluator:",
                                content: "Checking the answer 'Paris' for the capital of France...\nParis is the correct capital of France!\nrt = 1 ✓"
                            }
                        ]
                    }
                ];

                function sleep(ms) {
                    return new Promise(resolve => setTimeout(resolve, ms));
                }

                function highlightKeywords(text) {
                    return text
                        .replace(/\b(Input|Thought|Action|Observation|Answer|Task|Output|Result|Retrieved reflection|Memory|rt|Reflection):/g, '<span class="bold-keyword">$1:</span>')
                        .replace(/What is the capital[^?]*\?/g, '<span class="prompt-text">$&</span>')
                        .replace(/What country is the Eiffel Tower in[^?]*\?/g, '<span class="prompt-text">$&</span>')
                        .replace(/\b(rt = 0|rt = 1|❌|✓)\b/g, '<span class="bold-keyword">$1</span>')
                        .replace(/\bINPUT:/g, '<span class="bold-keyword">INPUT:</span>');
                }

                function createIteration(data, isReflexion = false, isLast = false) {
                    const iterationDiv = document.createElement('div');
                    iterationDiv.className = 'iteration';
                    iterationDiv.id = `${isReflexion ? 'reflexion-' : 'react-'}iteration-${data.number}`;

                    iterationDiv.innerHTML = `
                <div class="iteration-header">
                    <div class="iteration-number">${data.number}</div>
                    <div class="iteration-title">${data.title}</div>
                </div>
                <div class="iteration-content" id="${isReflexion ? 'reflexion-' : 'react-'}content-${data.number}">
                    </div>
                ${isReflexion && !isLast ? '<div class="iteration-connector">↓</div>' : ''}
            `;

                    return iterationDiv;
                }

                function createStep(stepData) {
                    const stepDiv = document.createElement('div');
                    stepDiv.className = `step ${stepData.type}-step`;

                    stepDiv.innerHTML = `
                <div class="step-label">${stepData.icon} ${stepData.label}</div>
                <div class="step-content">${highlightKeywords(stepData.content)}</div>
                ${stepData.type === 'observation' ? '<div class="source-indicator">Retrieved from knowledge base/internet</div>' : ''}
                ${stepData.type === 'memory' && stepData.label.includes('Update') ? '<div class="source-indicator">Stored for future trials</div>' : ''}
                ${stepData.type === 'memory' && stepData.label.includes('Retrieval') ? '<div class="source-indicator">Retrieved from previous trial</div>' : ''}
            `;

                    return stepDiv;
                }

                function createFlowIndicator(from, to) {
                    const flowDiv = document.createElement('div');
                    flowDiv.className = 'flow-indicator';

                    flowDiv.innerHTML = `
                <div class="flow-box">${from}</div>
                <div class="flow-arrow">→</div>
                <div class="flow-box">${to}</div>
            `;

                    return flowDiv;
                }

                function createDecisionBox(content, type = '') {
                    const decisionDiv = document.createElement('div');
                    decisionDiv.className = `decision-box ${type}`;
                    decisionDiv.innerHTML = content;
                    return decisionDiv;
                }

                function createArrow() {
                    const arrowDiv = document.createElement('div');
                    arrowDiv.className = 'arrow';
                    arrowDiv.innerHTML = '↓';
                    return arrowDiv;
                }

                // ReAct Animation Functions
                async function startReactAnimation() {
                    if (isReactAnimating) return;

                    isReactAnimating = true;

                    const container = document.getElementById('reactLoopContainer');
                    container.innerHTML = '';
                    document.getElementById('reactFinalAnswer').classList.remove('show');

                    for (let i = 0; i < reactIterationData.length; i++) {
                        await animateReactIteration(i);
                        await sleep(500);
                    }

                    // Show final answer
                    await sleep(800);
                    document.getElementById('reactFinalAnswer').classList.add('show');

                    isReactAnimating = false;
                }

                async function animateReactIteration(index) {
                    const data = reactIterationData[index];
                    const iterationElement = createIteration(data, false);
                    document.getElementById('reactLoopContainer').appendChild(iterationElement);

                    // Show iteration
                    await sleep(200);
                    iterationElement.classList.add('show');
                    await sleep(400);

                    const contentElement = document.getElementById(`react-content-${data.number}`);

                    // Add steps one by one
                    for (let stepIndex = 0; stepIndex < data.steps.length; stepIndex++) {
                        const stepData = data.steps[stepIndex];
                        const stepElement = createStep(stepData);
                        contentElement.appendChild(stepElement);

                        await sleep(300);
                        stepElement.classList.add('show');

                        // Add thinking animation for LLM steps
                        if (stepData.type === 'llm') {
                            const thinkingDiv = document.createElement('div');
                            thinkingDiv.className = 'thinking-dots';
                            thinkingDiv.innerHTML = '<span class="dot"></span><span class="dot"></span><span class="dot"></span>';
                            stepElement.appendChild(thinkingDiv);

                            await sleep(2500);
                            thinkingDiv.remove();
                        }

                        // Add flow indicators
                        if (stepIndex === 0 && stepData.type === 'input') {
                            const flowIndicator = createFlowIndicator('USER', 'LLM');
                            contentElement.appendChild(flowIndicator);
                            await sleep(200);
                            flowIndicator.classList.add('show');
                        } else if (stepData.type === 'llm' && stepData.content.includes('Action:')) {
                            const flowIndicator = createFlowIndicator('LLM', 'ACTION CONTROLLER');
                            contentElement.appendChild(flowIndicator);
                            await sleep(200);
                            flowIndicator.classList.add('show');
                        } else if (stepData.type === 'action') {
                            const flowIndicator = createFlowIndicator('CONTROLLER', 'KNOWLEDGE/INTERNET');
                            contentElement.appendChild(flowIndicator);
                            await sleep(200);
                            flowIndicator.classList.add('show');
                        }

                        // Add decision boxes for action and answer detection
                        if (stepData.content.includes('Action:') && !stepData.content.includes('Answer:')) {
                            const decisionBox = createDecisionBox('Action detected: YES → Execute action');
                            contentElement.appendChild(decisionBox);
                            await sleep(200);
                            decisionBox.classList.add('show');
                        } else if (stepData.content.includes('Answer:')) {
                            const decisionBox = createDecisionBox('Answer detected: YES → Stop loop');
                            contentElement.appendChild(decisionBox);
                            await sleep(200);
                            decisionBox.classList.add('show');
                        }

                        // Add arrow between steps (except last)
                        if (stepIndex < data.steps.length - 1) {
                            const arrow = createArrow();
                            contentElement.appendChild(arrow);
                            await sleep(100);
                            arrow.classList.add('show');
                        }

                        await sleep(600);
                    }
                }

                // Reflexion Animation Functions
                async function startReflexionAnimation() {
                    if (isReflexionAnimating) return;

                    isReflexionAnimating = true;

                    const container = document.getElementById('reflexionLoopContainer');
                    container.innerHTML = '';
                    document.getElementById('reflexionFinalAnswer').classList.remove('show');

                    // Create all iterations first
                    for (let i = 0; i < reflexionIterationData.length; i++) {
                        const iterationElement = createIteration(reflexionIterationData[i], true, i === reflexionIterationData.length - 1);
                        container.appendChild(iterationElement);
                    }

                    // Animate iterations one by one
                    for (let i = 0; i < reflexionIterationData.length; i++) {
                        await animateReflexionIteration(i);

                        // Show connector arrow after iteration is complete (except for last iteration)
                        if (i < reflexionIterationData.length - 1) {
                            const connector = document.querySelector(`#reflexion-iteration-${i + 1} .iteration-connector`);
                            if (connector) {
                                await sleep(300);
                                connector.classList.add('show');
                            }
                        }

                        await sleep(500);
                    }

                    // Show final answer
                    await sleep(800);
                    document.getElementById('reflexionFinalAnswer').classList.add('show');

                    isReflexionAnimating = false;
                }

                async function animateReflexionIteration(index) {
                    const data = reflexionIterationData[index];
                    const iterationElement = document.getElementById(`reflexion-iteration-${data.number}`);

                    // Show iteration
                    await sleep(200);
                    iterationElement.classList.add('show');
                    await sleep(400);

                    const contentElement = document.getElementById(`reflexion-content-${data.number}`);

                    // Add steps one by one
                    for (let stepIndex = 0; stepIndex < data.steps.length; stepIndex++) {
                        const stepData = data.steps[stepIndex];
                        const stepElement = createStep(stepData);
                        contentElement.appendChild(stepElement);

                        await sleep(300);
                        stepElement.classList.add('show');

                        // Add thinking animation for Actor and Self-Reflection steps
                        if (stepData.type === 'actor' || stepData.type === 'self-reflection') {
                            const thinkingDiv = document.createElement('div');
                            thinkingDiv.className = 'thinking-dots';
                            thinkingDiv.innerHTML = '<span class="dot"></span><span class="dot"></span><span class="dot"></span>';
                            stepElement.appendChild(thinkingDiv);

                            await sleep(stepData.type === 'self-reflection' ? 3000 : 2000);
                            thinkingDiv.remove();
                        }

                        // Add flow indicators
                        if (stepData.type === 'task') {
                            const flowIndicator = createFlowIndicator('TASK', 'ACTOR');
                            contentElement.appendChild(flowIndicator);
                            await sleep(200);
                            flowIndicator.classList.add('show');
                        } else if (stepData.type === 'actor') {
                            const flowIndicator = createFlowIndicator('ACTOR', 'EVALUATOR');
                            contentElement.appendChild(flowIndicator);
                            await sleep(200);
                            flowIndicator.classList.add('show');
                        } else if (stepData.type === 'evaluator' && stepData.content.includes('rt = 0')) {
                            const flowIndicator = createFlowIndicator('EVALUATOR', 'REFLECTION');
                            contentElement.appendChild(flowIndicator);
                            await sleep(200);
                            flowIndicator.classList.add('show');
                        } else if (stepData.type === 'evaluator' && stepData.content.includes('rt = 1')) {
                            const flowIndicator = createFlowIndicator('EVALUATOR', 'SUCCESS');
                            contentElement.appendChild(flowIndicator);
                            await sleep(200);
                            flowIndicator.classList.add('show');
                        }

                        // Add decision boxes
                        if (stepData.type === 'evaluator') {
                            const decisionType = stepData.content.includes('rt = 1') ? 'success' : 'failure';
                            const decisionText = stepData.content.includes('rt = 1') ? 'Correct! ✓ Stop loop.' : 'Incorrect! ❌ Reflect and retry.';
                            const decisionBox = createDecisionBox(decisionText, decisionType);
                            contentElement.appendChild(decisionBox);
                            await sleep(200);
                            decisionBox.classList.add('show');
                        }

                        // Add arrow between steps (except last)
                        if (stepIndex < data.steps.length - 1) {
                            const arrow = createArrow();
                            contentElement.appendChild(arrow);
                            await sleep(100);
                            arrow.classList.add('show');
                        }

                        await sleep(600);
                    }
                }

                // Start animations when the page loads
                document.addEventListener('DOMContentLoaded', () => {
                    // No auto-start, rely on buttons
                });
            </script>
        </body>

</html>
</section>

<section id="tool-usage">
    <div class="projects-header">
        <h1>Tool Usage</h1>
    </div>

    <div class="projects-container">
        <!-- Card 1 -->
        <div class="project-box">
            <h2>What are tools?</h2>
            <blockquote style="border-left:3px solid #000;padding-left:1em;opacity:0.8;">
                “In the context of agentic LLMs, tool use refers to the model's ability
                to interact with external tools, APIs, or functions to perform tasks it
                cannot accomplish through language generation alone.”
                <sup>Wooldridge & Jennings, 1995</sup>
            </blockquote>
            <p><strong>Enables LLMs to:</strong></p>
            <ul>
                <li>Make API calls or execute functions</li>
                <li>Perform real-world operations instead of hallucinating answers</li>
            </ul>
        </div>

        <!-- Card 2 -->
        <div class="project-box">
            <h2>Why do LLMs need tools?</h2>
            <ul>
                <li>LLMs struggle with arithmetic, dates, factual lookups <sup>Schick et al., 2023</sup>.</li>
                <li>Toolformer demonstrates self-supervised tool usage <sup>Schick et al., 2023</sup>.</li>
                <li>Benchmarks show strong improvements with calculators & retrieval <sup>Nakano et al., 2021</sup>.
                </li>
            </ul>
            <img src="images/3_new/03.png" alt="Performance graph" style="width:100%;border-radius:0.5em;" />
        </div>

        <!-- Card 3: Interactive Demo -->
        <div class="project-box">
            <h2>Try it yourself</h2>
            <p>Simulate a tool call: ask a math question (e.g. <code>123 * 45</code>)</p>
            <input id="userPrompt" type="text" placeholder="Enter a math question"
                style="width:100%;padding:0.8em;border-radius:0.5em;border:1px solid #000;" />
            <br /><br />
            <button class="btn" onclick="runToolDemo()">Run Tool Demo</button>
            <pre id="demoOutput" style="margin-top:1em;opacity:0.8;"></pre>
            <p style="font-size:0.85em;opacity:0.7;margin-top:0.6em;">Inspired by WebGPT’s tool-augmented setup
                <sup>Nakano et al., 2021</sup>.
            </p>
        </div>

        <!-- Card 4 -->
        <div class="project-box">
            <h2>How LLMs learn tool use</h2>
            <ol style="text-align:left;">
                <li>Model generates text and inserts tool calls</li>
                <li>Tool calls are executed; outputs appended</li>
                <li>Model checks if tool calls improved prediction</li>
                <li>Only useful interactions are retained for training <sup>Schick et al., 2023</sup></li>
            </ol>
            <img src="images/3_new/01.png" alt="Learning process" style="width:100%;border-radius:0.5em;" />
        </div>

        <!-- Card 5 -->
        <div class="project-box">
            <h2>Scenarios where tools are useful</h2>
            <div style="display:flex;gap:2em;flex-wrap:wrap;">
                <div style="flex:1;min-width:250px;text-align:left;">
                    <ol>
                        <li>Knowledge Access (SQL, Search, RAG)</li>
                        <li>Computation (Calculators, Spreadsheets)</li>
                        <li>World Interaction (Calendars, Embodied agents)</li>
                    </ol>
                </div>
                <div style="flex:1;min-width:250px;text-align:left;">
                    <ol start="4">
                        <li>Non-Text Modalities (Image APIs, Audio APIs)</li>
                        <li>Specialized Models (Domain LMs, orchestration)</li>
                    </ol>
                </div>
            </div>
            <p style="font-size:0.85em;opacity:0.7;margin-top:0.6em;">Examples drawn from applied AI frameworks
                <sup>OpenAI, 2022</sup>.
            </p>
        </div>

        <!-- Card 6 -->
        <div class="project-box">
            <h2>When tools are less effective</h2>
            <ul style="text-align:left;">
                <li>Machine translation, summarization, sentiment analysis</li>
                <li>Tasks where base LLMs already outperform specialized tools <sup>OpenAI, 2023</sup></li>
            </ul>
        </div>

        <!-- New Card: Framework Profiles -->
        <div class="project-box">
            <h2>Key Frameworks and Services</h2>

            <h3>🔎 WebGPT</h3>
            <p><em>Use-Case:</em> Search-augmented LLM with citations. <sup>Nakano et al., 2021</sup></p>
            <p><em>Strengths:</em> Reduces hallucinations, improves transparency.</p>
            <p><em>Limitations:</em> Dependent on search quality; slower responses.</p>

            <h3>🧩 LlamaIndex</h3>
            <p><em>Use-Case:</em> Retrieval over large corpora (PDFs, enterprise docs). <sup>LlamaIndex Docs, 2025</sup>
            </p>
            <p><em>Strengths:</em> Modular, scalable, efficient retrieval.</p>
            <p><em>Limitations:</em> Requires setup & integration; not a full orchestration framework.</p>

            <h3>🤝 AutoGen</h3>
            <p><em>Use-Case:</em> Multi-agent orchestration with specialized roles. <sup>Microsoft, 2023</sup></p>
            <p><em>Strengths:</em> Flexible agent conversations, tool coordination.</p>
            <p><em>Limitations:</em> Setup complexity, requires monitoring.</p>
        </div>

        <!-- New Card: Example Code -->
        <div class="project-box">
            <h2>Example: Calling a Tool</h2>
            <div class="code-block">
                <span class="code-comment"># Example: LLM using a calculator tool</span><br>
                <span class="code-keyword">user:</span> "What is 256 * 47?"<br><br>
                <span class="code-keyword">LLM thought:</span> I should multiply these numbers.<br>
                <span class="code-keyword">LLM action:</span> call(Calculator, "256 * 47")<br><br>
                <span class="code-keyword">Tool output:</span> "12032"<br>
                <span class="code-keyword">LLM answer:</span> "The result is 12,032." <sup>Schick et al., 2023</sup>
            </div>
            <p style="font-size:0.85em;opacity:0.7;">Adapted from Toolformer’s tool-augmented training.</p>
        </div>

        <!-- 🔹 New Card: Interactive Comparison -->
        <div class="project-box">
            <h2>LLM vs Tool-Augmented LLM</h2>
            <p>Toggle to compare performance:</p>
            <button class="btn" onclick="toggleComparison()">Switch View</button>
            <div id="comparisonBox"
                style="margin-top:1rem;padding:1rem;border:1px solid #000;border-radius:0.5em;background:#fafafa;">
                <h4>Standard LLM</h4>
                <p>Answers questions based on training data only. Struggles with live facts, arithmetic, and external
                    APIs.</p>
            </div>
            <p style="font-size:0.85em;opacity:0.7;margin-top:0.6em;">Comparison based on WebGPT experiments
                <sup>Nakano et al., 2021</sup>.
            </p>
        </div>
    </div>
</section>

<script>
    function runToolDemo() {
        const input = document.getElementById("userPrompt").value;
        let output = "";
        try {
            const match = input.match(/(\d+)\s*([+\-*/])\s*(\d+)/);
            if (match) {
                const a = parseFloat(match[1]);
                const op = match[2];
                const b = parseFloat(match[3]);
                switch (op) {
                    case "+": output = a + b; break;
                    case "-": output = a - b; break;
                    case "*": output = a * b; break;
                    case "/": output = b !== 0 ? a / b : "Error: divide by zero"; break;
                }
            } else {
                output = "This demo only supports simple arithmetic (e.g. 12 * 34)";
            }
        } catch (err) {
            output = "Error: " + err.message;
        }
        document.getElementById("demoOutput").textContent = "Tool Output: " + output;
    }

    function toggleComparison() {
        const box = document.getElementById("comparisonBox");
        if (box.dataset.mode === "tool") {
            box.innerHTML = `
        <h4>Standard LLM</h4>
        <p>Answers questions based on training data only. Struggles with live facts, arithmetic, and external APIs.</p>
      `;
            box.dataset.mode = "llm";
        } else {
            box.innerHTML = `
        <h4>Tool-Augmented LLM</h4>
        <p>Can call calculators, query search engines, and retrieve real-time knowledge. Reduces hallucinations and improves accuracy.</p>
      `;
            box.dataset.mode = "tool";
        }
    }
</script>


<section id="software_engineering">
    <div class="projects-header">
        <h1>Software Engineering</h1>
    </div>
    <div class="container">
        <div class="main-content">

            <!-- Bug Localizer -->
            <div class="content-section">
                <h2><i class="fas fa-bug"></i> Bug Localizer: The Perfect Example</h2>
                <p>Let's start with a concrete example that perfectly illustrates the power of AI agents in software
                    engineering - the Bug Localizer.</p>
                <div class="quote">
                    "What would take a human developer potentially hours of manual debugging, the AI agent
                    accomplishes in minutes."
                </div>

                <div class="comparison">
                    <div class="comparison-card">
                        <h4><i class="fas fa-user-clock"></i> Traditional Debugging</h4>
                        <ul>
                            <li>Manual log reading</li>
                            <li>Time-consuming process</li>
                            <li>Error-prone approach</li>
                            <li>Relies on intuition</li>
                            <li>Limited context awareness</li>
                        </ul>
                    </div>
                    <div class="comparison-card">
                        <h4><i class="fas fa-robot"></i> AI Agent Debugging</h4>
                        <ul>
                            <li>Processes logs and code simultaneously</li>
                            <li>Accesses entire repository</li>
                            <li>Applies debugging heuristics</li>
                            <li>Rule-based checks</li>
                            <li>Comprehensive reporting</li>
                        </ul>
                    </div>
                </div>

                <p>This isn't just about speed - it's about <span class="highlight">consistency and accuracy</span>.
                    The agent doesn't get tired, doesn't overlook details, and doesn't carry cognitive biases that
                    might lead us down the wrong debugging path.</p>
            </div>

            <!-- Framework -->
            <div class="content-section">
                <h2><i class="fas fa-sitemap"></i> Framework: How It All Works</h2>
                <p>So how does this magic happen? Let's look at the underlying framework that makes AI agents so
                    powerful in software engineering.</p>
                <div class="framework-image">
                    <div class="framework-image-placeholder">
                        <img src="images/4/framework.png" style="width: 40vw; min-width: 330px;"
                            alt="reference framework diagram">
                    </div>
                </div>
                <p class="framework-caption">Figure 1: Conceptual framework for AI agents in software engineering.
                </p>

                <div class="framework-diagram">
                    <div class="framework-step">
                        <div class="step-icon"><i class="fas fa-eye"></i></div>
                        <h4>Perception</h4>
                        <p>Processing inputs from various sources</p>
                    </div>
                    <div class="framework-step">
                        <div class="step-icon"><i class="fas fa-brain"></i></div>
                        <h4>Reasoning</h4>
                        <p>Analyzing information and making decisions</p>
                    </div>
                    <div class="framework-step">
                        <div class="step-icon"><i class="fas fa-bolt"></i></div>
                        <h4>Action</h4>
                        <p>Executing tasks based on decisions</p>
                    </div>
                </div>

                <p>What makes this framework particularly powerful is the <span class="highlight">feedback
                        loop</span>. The agent can observe the results of its actions, learn from outcomes, and
                    iteratively improve its approach - just like an experienced developer would.</p>
            </div>

            <!-- Perception -->
            <div class="content-section">
                <h2><i class="fas fa-eye"></i> Perception: The Agent's Input System</h2>
                <p>Let's dive deeper into how AI agents perceive and process information in software engineering
                    contexts.</p>
                <h3><i class="fas fa-code"></i> Multi-modal Input Processing</h3>
                <ul class="icon-list">
                    <li><i class="fas fa-check-circle"></i> <strong>Code as text:</strong> Reading and understanding
                        syntax, semantics, and structure</li>
                    <li><i class="fas fa-check-circle"></i> <strong>Abstract Syntax Trees:</strong> Understanding
                        hierarchical relationships</li>
                    <li><i class="fas fa-check-circle"></i> <strong>Visual inputs:</strong> Interpreting UML
                        diagrams and UI sketches</li>
                    <li><i class="fas fa-check-circle"></i> <strong>Natural language:</strong> Processing
                        requirements and documentation</li>
                </ul>

                <div class="code-visualization">
                    <div class="code-visual">
                        <h4><i class="fas fa-file-code"></i> Code as Text</h4>
                        <div class="code-block">
                            <span class="code-comment"># Calculate factorial of a number</span><br>
                            <span class="code-keyword">def</span> <span class="code-function">factorial</span>(n):<br>
                            &nbsp;&nbsp;<span class="code-keyword">if</span> n == <span
                                class="code-number">0</span>:<br>
                            &nbsp;&nbsp;&nbsp;&nbsp;<span class="code-keyword">return</span> <span
                                class="code-number">1</span><br>
                            &nbsp;&nbsp;<span class="code-keyword">else</span>:<br>
                            &nbsp;&nbsp;&nbsp;&nbsp;<span class="code-keyword">return</span> n * factorial(n-1)<br>
                            <br>
                            <span class="code-comment"># Print result</span><br>
                            <span class="code-keyword">print</span>(<span class="code-string">"Factorial of 5
                                is:"</span>, factorial(<span class="code-number">5</span>))
                        </div>
                    </div>

                    <div class="code-visual">
                        <h4><i class="fas fa-project-diagram"></i> Abstract Syntax Tree</h4>
                        <div class="syntax-tree">
                            <div class="tree-node">
                                <div class="node-value">fn</div>
                                Function
                                <div class="tree-children">
                                    <div class="tree-node">
                                        <div class="node-value">id</div> factorial
                                    </div>
                                    <div class="tree-node">
                                        <div class="node-value">p</div> Parameters
                                        <div class="tree-children">
                                            <div class="tree-node">
                                                <div class="node-value">n</div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="tree-node">
                                        <div class="node-value">b</div> Body
                                        <div class="tree-children">
                                            <div class="tree-node">
                                                <div class="node-value">if</div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <p>The <span class="highlight">multi-modal nature of perception</span> is what makes these agents so
                    powerful…</p>
            </div>

            <!-- Memory -->
            <div class="content-section">
                <h2><i class="fas fa-brain"></i> Memory: Maintaining Context and Learning</h2>
                <p>Memory is what separates sophisticated AI agents from simple code generators…</p>
                <div class="memory-types">
                    <div class="memory-card">
                        <h4><i class="fas fa-history"></i> Short-term Memory</h4>
                        <ul class="icon-list">
                            <li><i class="fas fa-circle-notch"></i> Maintains context during development sessions
                            </li>
                            <li><i class="fas fa-circle-notch"></i> Tracks code changes in real-time</li>
                        </ul>
                    </div>
                    <div class="memory-card">
                        <h4><i class="fas fa-database"></i> Long-term Memory</h4>
                        <ul class="icon-list">
                            <li><i class="fas fa-circle-notch"></i> Learns from past experiences</li>
                            <li><i class="fas fa-circle-notch"></i> Tracks project history and evolution</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- Cline -->
            <div id="cline" class="content-section">
                <h2><i class="fas fa-code"></i> Cline-CoPilot in Action</h2>
                <p>Cline is an AI agent specifically designed for software engineering tasks…</p>
                <h3><i class="fas fa-cogs"></i> Cline's Web Development Process</h3>
                <ol class="icon-list">
                    <li><i class="fas fa-arrow-right"></i> Initialization Protocol</li>
                    <li><i class="fas fa-arrow-right"></i> Design Analysis</li>
                    <li><i class="fas fa-arrow-right"></i> Component Implementation</li>
                    <li><i class="fas fa-arrow-right"></i> Accessibility Integration</li>
                </ol>
                <div class="comparison">
                    <div class="comparison-card">
                        <h4><i class="fas fa-paint-brush"></i> Design Phase</h4>
                        <ul>
                            <li>References designBrief.md</li>
                            <li>Applies brandContext.md</li>
                        </ul>
                    </div>
                    <div class="comparison-card">
                        <h4><i class="fas fa-code"></i> Development Phase</h4>
                        <ul>
                            <li>Implements componentLibrary.md</li>
                            <li>Ensures accessibility compliance</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- Evaluation -->
            <div class="content-section">
                <h2><i class="fas fa-clipboard-check"></i> Evaluating AI Coding Agents</h2>
                <p>Evaluating a web development AI coding agent is a complex task…</p>
                <h3><i class="fas fa-chart-line"></i> Core Performance Metrics</h3>
                <div class="evaluation-grid">
                    <div class="evaluation-card">
                        <h4><i class="fas fa-check-double"></i> Accuracy & Correctness</h4>
                        <ul>
                            <li>Syntactic correctness</li>
                            <li>Bug detection & fixes</li>
                        </ul>
                    </div>
                    <div class="evaluation-card">
                        <h4><i class="fas fa-tachometer-alt"></i> Efficiency & Optimization</h4>
                        <ul>
                            <li>Performance</li>
                            <li>Resource usage</li>
                        </ul>
                    </div>
                </div>
            </div>

        </div>
    </div>

</section>



<section id="risks">
    <div class="projects-header">
        <h1>Risks</h1>
    </div>

    <div class="projects-container">
        <div class="project-box">
            <p>
                Now that we saw all the possible utilizations of LLMs, let's talk risk. For example, a
                government agency utilizing language agents to automate part of their process. This happens all
                over the place and lately in Potsdam as well when it comes to housing benefit
                applications.<sup><a
                        href="https://www.potsdam.de/de/151-potsdam-startet-ki-unterstuetzte-wohngeld-antragsbearbeitung"
                        class="reference">[1]</a></sup>
            </p>

            <p>
                The capabilities of the implementation are unknown, but automatic answering of emails,
                checking for application completeness, and a chatbot for workers of the municipality are part of
                the discussion.
            </p>

            <img src="images/5/email.png" alt="Email Illustration" style="max-width:400px; border-radius:0.5em;">

            <p>
                This illustrates what could go wrong, and as reliable agents, which always follow the system
                prompt, are quite rare, security systems need to be in place. The two main goals are that a
                language agent should never violate the privacy requirements (e.g., hand out information about
                other applicants) and should never misuse tools (e.g., generate faulty emails).
            </p>
        </div>

        <div class="project-box">
            <h2>Potential Weaknesses</h2>

            <img src="images/5/core-loop.png" alt="Core Loop Illustration" style="width:100%; border-radius:0.5em;">

            <h3>Input</h3>
            <p>
                The input is the main source of malicious or harmful information. The biggest risk is prompt
                injections<sup><a href="https://arxiv.org/abs/2503.18813" class="reference">[2]</a></sup>,
                which aim to get the language agent to behave outside its intended scope.
            </p>

            <p>
                Imagine a language agent controlled via chat. There should be administrators with the ability to
                alter its behavior while you wouldn't want it to do what a
                normal user instructs it to. This necessitates the difficult ability to differentiate
                between contexts and privileges of users.
            </p>

            <div class="text">
                This is a small game on prompt injections, made by h43z, where you try to get the LLM to reveal its
                secrets.
            </div>
            <iframe id="dynamicIframe" src="https://gpa.43z.one/"
                style="border:1px solid #ddd; border-radius:0.5em; width:100%;"></iframe>
        </div>

        <div class="project-box">
            <h3>Output</h3>
            <p>
                The output is where faulty input or faulty reasoning leads to real problems.
            </p>
            <p>
                A language agent might violate privacy by handing out information not intended for the specific
                user.
                This shows that output context also needs to be considered.
            </p>
            <p>
                Another risk is misuse of tools. A language agent mishandling a database might make all successive
                tasks impossible, causing long-term harm. More powerful tools need stronger protection.
            </p>
        </div>

        <div class="project-box">
            <h2>Methods</h2>
            <p>
                Google details methods to counteract these problems.<sup><a
                        href="https://research.google/pubs/an-introduction-to-googles-approach-for-secure-ai-agents/"
                        class="reference">[3]</a></sup>
            </p>

            <img src="images/5/security.png" alt="Security Illustration" style="width:100%; border-radius:0.5em;">

            <h3>Traditional</h3>
            <p>
                Limit input and output of the LLM. Filter harmful prompts and exclude sensitive data.
                Standardize APIs to prevent misuse. Use IT security practices like testing, logging, and human
                oversight.
            </p>

            <h3>Reasoning</h3>
            <p>
                Google proposes “soft constraints” to allow helpful emergent behavior. This includes adversarial
                training
                and LLM-based guard models that analyze and predict harmful behavior. These systems may limit
                privileges or require human intervention.
                <sup><a href="https://arxiv.org/abs/2402.01817" class="reference">[4]</a></sup>
            </p>
        </div>

        <div class="project-box">
            <h2>Societal Implications</h2>
            <p class="quote">“Everyone wants to generate texts with AI. No one wants to read AI generated texts.”
            </p>

            <p>
                Municipalities may automate emails, but this can increase workload for citizens. There is an
                inherent conflict
                of interest between users and developers.
            </p>

            <p>
                Google and Potsdam both point to human supervision. But humans tend to lose vigilance when systems
                perform
                reliably. AI agents should only be used if they surpass humans without supervision.
                <sup><a href="https://arxiv.org/abs/2402.01817" class="reference">[5]</a></sup>
            </p>

            <p>
                With that in mind, consider carefully whether a language agent is the correct solution for your
                problem.
            </p>

            <img src="images/5/societal.png" alt="Societal Implications Illustration"
                style="width:100%; border-radius:0.5em;">
        </div>
    </div>

    <script>
        function adjustIframeSize() {
            const textElement = document.querySelector('#risks .text');
            const iframe = document.querySelector('#risks #dynamicIframe');
            if (!textElement || !iframe) return;
            const textWidth = textElement.offsetWidth;
            iframe.style.width = textWidth + 'px';
            iframe.style.height = (textWidth * 0.6667) + 'px';
        }
        window.addEventListener('resize', adjustIframeSize);
        window.addEventListener('load', adjustIframeSize);
    </script>
</section>

<section id="about">
    <div class="info-box">
        <h1><span>Meet the Team</span></h1>
    </div>

    <div class="skills">
        <ul>
            <li><span>Felix Kratzsch</span></li>
            <li><span>Maximilian Krupop</span></li>
            <li><span>Jarred Boere</span></li>
            <li><span>Uday Kale</span></li>
            <li><span>Jayesh Choudhari</span></li>
        </ul>
    </div>
</section>


<footer>
    <div class="col-left">
        <div class="col-box">
            <span><i class='bx bxs-envelope'></i></span>
            <span>
                jboere01@gmail.com
            </span>
        </div>

        <div class="col-box">
            <span><i class='bx bxs-phone'></i></span>
            <span>
                +49 176 80431522
            </span>
        </div>
    </div>
    <div class="col-right">
        <div class="social-icons">
            <span>
                <a href="https://www.linkedin.com/in/jarred-boere" target="_blank">
                    <i class='bx bxl-linkedin-square'></i>
                </a>
            </span>
            <span>
                <a href="https://github.com/JazaB123" target="_blank">
                    <i class='bx bxl-github'></i>
                </a>
            </span>
        </div>
</footer>

<script src="script.js"></script>
</body>

</html>